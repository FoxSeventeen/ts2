# index_core.py
import pickle
import os
from db_core import read_csv, DATA_DIR, INDEX_DIR  # å¯¼å…¥æ ¸å¿ƒæ¨¡å—å’Œè·¯å¾„å¸¸é‡


# -------------------------- æœ‰åºç´¢å¼•ï¼ˆå¿«é€’å•å·ï¼‰--------------------------
def build_order_index():
    """æ„å»ºå¿«é€’å•å·æœ‰åºç´¢å¼•ï¼ˆåŸºäºB+æ ‘ç®€åŒ–ï¼‰"""
    file_path = "database/data/ExpressOrder.csv"
    index_path = "database/index/ExpressOrder_orderId.idx"
    orders = read_csv(file_path)

    # ç”Ÿæˆç´¢å¼•ï¼š{å¿«é€’å•å·: [è¡Œå·1, è¡Œå·2,...]}ï¼ˆè¡Œå·ä»2å¼€å§‹ï¼Œé¦–è¡Œä¸ºåˆ—åï¼‰
    index_dict = {}
    for row_num, order in enumerate(orders, start=2):
        order_id = order['orderId']
        if order_id not in index_dict:
            index_dict[order_id] = []
        index_dict[order_id].append(row_num)

    # ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶ï¼ˆæ–‡æœ¬æ ¼å¼ï¼Œä¾¿äºæŸ¥çœ‹ï¼‰
    with open(index_path, 'w', encoding='utf-8') as f:
        for order_id, row_nums in index_dict.items():
            f.write(f"{order_id},{','.join(map(str, row_nums))}\n")
    print("å¿«é€’å•å·æœ‰åºç´¢å¼•æ„å»ºå®Œæˆ")


def search_order_index(order_id):
    """æŸ¥è¯¢å¿«é€’å•å·æœ‰åºç´¢å¼•ï¼Œè¿”å›åŒ¹é…è¡Œå·"""
    index_path = "database/index/ExpressOrder_orderId.idx"
    try:
        with open(index_path, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split(',')
                if parts[0] == order_id:
                    return list(map(int, parts[1:]))
        return []
    except FileNotFoundError:
        print("ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºç´¢å¼•")
        build_order_index()
        return search_order_index(order_id)


# -------------------------- æ•£åˆ—ç´¢å¼•ï¼ˆç”¨æˆ·æ‰‹æœºå·ï¼‰--------------------------


class HashIndex:
    def __init__(self, table_name, index_col, bucket_count=200):
        """
        åˆå§‹åŒ–å“ˆå¸Œç´¢å¼•
        :param table_name: è¡¨åï¼ˆå¦‚"User"ã€"ExpressOrder"ï¼‰
        :param index_col: ç´¢å¼•å­—æ®µï¼ˆå¦‚"uphone"ã€"orderId"ï¼‰
        :param bucket_count: å“ˆå¸Œæ¡¶æ•°é‡ï¼ˆé»˜è®¤200ï¼Œå¯æ ¹æ®æ•°æ®é‡è°ƒæ•´ï¼‰
        """
        self.table_name = table_name
        self.index_col = index_col
        self.bucket_count = bucket_count
        self.buckets = [[] for _ in range(bucket_count)]  # é“¾åœ°å€æ³•å­˜å‚¨ (ç´¢å¼•å€¼, è¡Œå·)
        self.loaded = False  # æ ‡è®°ç´¢å¼•æ˜¯å¦å·²åŠ è½½

    def build(self):
        """ä»æ•°æ®è¡¨æ„å»ºç´¢å¼•ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰"""
        # 1. è¯»å–æ•°æ®è¡¨
        table_path = f"{DATA_DIR}/{self.table_name}.csv"
        data = read_csv(table_path)
        if not data:
            print(f"è­¦å‘Šï¼š{self.table_name}.csv æ— æ•°æ®ï¼Œç´¢å¼•æ„å»ºä¸ºç©º")
            return False

        # 2. æ ¡éªŒç´¢å¼•å­—æ®µæ˜¯å¦å­˜åœ¨
        if self.index_col not in data[0]:
            print(f"é”™è¯¯ï¼šè¡¨{self.table_name}ä¸­ä¸å­˜åœ¨å­—æ®µ{self.index_col}ï¼Œç´¢å¼•æ„å»ºå¤±è´¥")
            return False

        # 3. æ„å»ºå“ˆå¸Œç´¢å¼•ï¼ˆé“¾åœ°å€æ³•å¤„ç†å†²çªï¼‰
        self.buckets = [[] for _ in range(self.bucket_count)]  # é‡ç½®æ¡¶
        for row_num, record in enumerate(data, start=2):  # è¡Œå·ä»2å¼€å§‹ï¼ˆé¦–è¡Œä¸ºåˆ—åï¼‰
            index_val = record[self.index_col]
            # è®¡ç®—å“ˆå¸Œå€¼å¹¶å–æ¨¡ï¼ˆç¡®ä¿æ¡¶ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´ï¼‰
            bucket_idx = hash(index_val) % self.bucket_count
            self.buckets[bucket_idx].append((index_val, row_num))

        # 4. ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶
        self.save()
        self.loaded = True  # æ ‡è®°ä¸ºå·²åŠ è½½
        print(f"âœ… ç´¢å¼•æ„å»ºå®Œæˆï¼š{self.table_name}_{self.index_col}ï¼ˆ{len(data)}æ¡æ•°æ®ï¼‰")
        return True

    def save(self):
        """å°†ç´¢å¼•ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆäºŒè¿›åˆ¶æ ¼å¼ï¼Œé«˜æ•ˆè¯»å†™ï¼‰"""
        # ç¡®ä¿ç´¢å¼•ç›®å½•å­˜åœ¨
        os.makedirs(INDEX_DIR, exist_ok=True)
        index_path = f"{INDEX_DIR}/{self.table_name}_{self.index_col}_hash.idx"

        # ä¿å­˜æ¡¶æ•°é‡å’Œæ¡¶æ•°æ®ï¼ˆä¾¿äºåŠ è½½æ—¶æ¢å¤ï¼‰
        with open(index_path, 'wb') as f:
            pickle.dump((self.bucket_count, self.buckets), f)

    def load(self):
        """åŠ è½½å·²ä¿å­˜çš„ç´¢å¼•æ–‡ä»¶ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™è‡ªåŠ¨æ„å»ºï¼‰"""
        if self.loaded:
            return True  # å·²åŠ è½½ï¼Œç›´æ¥è¿”å›

        index_path = f"{INDEX_DIR}/{self.table_name}_{self.index_col}_hash.idx"
        try:
            # è¯»å–ç´¢å¼•æ–‡ä»¶
            with open(index_path, 'rb') as f:
                self.bucket_count, self.buckets = pickle.load(f)
            self.loaded = True
            print(f"âœ… ç´¢å¼•åŠ è½½æˆåŠŸï¼š{self.table_name}_{self.index_col}")
            return True
        except FileNotFoundError:
            # ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨æ„å»º
            print(f"âš ï¸ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè‡ªåŠ¨æ„å»º...")
            return self.build()
        except Exception as e:
            print(f"âŒ ç´¢å¼•åŠ è½½å¤±è´¥ï¼š{e}ï¼Œå°è¯•é‡æ–°æ„å»º...")
            return self.build()

    def search(self, index_val):
        """
        æŸ¥è¯¢ç´¢å¼•ï¼Œè¿”å›åŒ¹é…çš„è¡Œå·åˆ—è¡¨
        :param index_val: è¦æŸ¥è¯¢çš„ç´¢å¼•å€¼ï¼ˆå¦‚æ‰‹æœºå·"13800138000"ï¼‰
        :return: åŒ¹é…çš„è¡Œå·åˆ—è¡¨ï¼ˆè¡Œå·å¯¹åº”æ•°æ®è¡¨ä¸­çš„å®é™…è¡Œï¼‰
        """
        # ç¡®ä¿ç´¢å¼•å·²åŠ è½½
        if not self.load():
            return []

        # è®¡ç®—ç›®æ ‡æ¡¶ç´¢å¼•
        bucket_idx = hash(index_val) % self.bucket_count
        # ä»æ¡¶ä¸­ç­›é€‰åŒ¹é…çš„è¡Œå·
        match_rows = [row_num for (val, row_num) in self.buckets[bucket_idx] if val == index_val]
        print(f"ğŸ” ç´¢å¼•æŸ¥è¯¢ç»“æœï¼š{self.index_col}={index_val} åŒ¹é…{len(match_rows)}æ¡è®°å½•")
        return match_rows

    def rebuild(self):
        """å¼ºåˆ¶é‡å»ºç´¢å¼•ï¼ˆç”¨äºæ•°æ®æ›´æ–°ååŒæ­¥ï¼‰"""
        print(f"ğŸ”„ å¼€å§‹é‡å»ºç´¢å¼•ï¼š{self.table_name}_{self.index_col}")
        return self.build()
# ä½¿ç”¨ç¤ºä¾‹ï¼ˆåç»­åœ¨main.pyæˆ–GUIä¸­è°ƒç”¨ï¼‰
if __name__ == "__main__":
    # æ„å»ºå¿«é€’å•å·æœ‰åºç´¢å¼•
    build_order_index()
    # æ„å»ºç”¨æˆ·æ‰‹æœºå·æ•£åˆ—ç´¢å¼•
    user_phone_index = HashIndex("User", "phone")
    user_phone_index.build()